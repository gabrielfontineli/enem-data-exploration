{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd90da7",
   "metadata": {},
   "source": [
    "\n",
    "# ENEM 2023 — 03 · Rótulos do Dicionário & Export Rotulada\n",
    "\n",
    "Objetivo: **ler o dicionário .xlsx**, aplicar rótulos legíveis às variáveis categóricas (ex.: `TP_ESCOLA`, `Q001–Q006`), \n",
    "e **salvar uma versão rotulada** do dataset para uso nos gráficos e no relatório.\n",
    "\n",
    "- Sem seaborn; apenas **matplotlib**.\n",
    "- Salva arquivos em:\n",
    "  - `../data/interim/enem_2023_rotulado.parquet`\n",
    "  - `../reports/figures/*`\n",
    "  - `../reports/tabelas/dicionario_mapeamentos.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6fbb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: /Users/gabrielfontineli/Documents/study/enem-data-exploration/data/interim/enem_2023.parquet\n",
      "Dicionário: /Users/gabrielfontineli/Documents/study/enem-data-exploration/data/interim/unzipped_2023/DICIONµRIO/Dicion†rio_Microdados_Enem_2023.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Caminhos (ajuste se necessário)\n",
    "PARQUET_IN = Path(\"../data/interim/enem_2023.parquet\").resolve()\n",
    "DICT_PATH  = Path(\"../data/interim/unzipped_2023/DICIONµRIO/Dicion†rio_Microdados_Enem_2023.xlsx\").resolve()\n",
    "\n",
    "PARQUET_OUT = Path(\"../data/interim/enem_2023_rotulado.parquet\").resolve()\n",
    "FIG_DIR     = Path(\"../reports/figures\"); FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR     = Path(\"../reports/tabelas\"); TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Usando:\", PARQUET_IN)\n",
    "print(\"Dicionário:\", DICT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d430a65f",
   "metadata": {},
   "source": [
    "## 1) Helper para ler o dicionário (.xlsx) e extrair rótulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93af1556",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_enem_dictionary(dict_path: str | Path, sheet_name: str = \"MICRODADOS_ENEM_2023\"):\n",
    "    df = pd.read_excel(dict_path, sheet_name=sheet_name, header=2)\n",
    "    # localizar colunas por palavras-chave (tolerante a acentos/maiúsculas)\n",
    "    def find_col(keyword):\n",
    "        for c in df.columns:\n",
    "            if keyword.lower() in str(c).lower():\n",
    "                return c\n",
    "        return None\n",
    "    col_var = find_col(\"variável\")\n",
    "    col_desc = find_col(\"descrição\")\n",
    "    col_cat = find_col(\"valor\") or find_col(\"categ\")\n",
    "    if not col_var or not col_desc:\n",
    "        raise ValueError(\"Não foi possível identificar colunas de variável/descrição no dicionário.\")\n",
    "    descriptions, categories = {}, {}\n",
    "    for _, row in df.iterrows():\n",
    "        var = str(row[col_var]).strip().upper()\n",
    "        if not var or var == \"NAN\":\n",
    "            continue\n",
    "        descriptions[var] = str(row[col_desc]).strip()\n",
    "        cats_raw = str(row[col_cat]) if col_cat else \"\"\n",
    "        pairs = []\n",
    "        for part in re.split(r\"[;\\n]+\", cats_raw):\n",
    "            m = re.match(r\"\\s*([A-Za-z0-9]+)\\s*[-=:\\u2013]\\s*(.+)\", part)\n",
    "            if m:\n",
    "                code, label = m.group(1).strip(), m.group(2).strip()\n",
    "                pairs.append((code, label))\n",
    "        if pairs:\n",
    "            categories[var] = {k: v for k, v in pairs}\n",
    "    return descriptions, categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c857165",
   "metadata": {},
   "source": [
    "## 2) Carregar base e dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bace4243",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/gabrielfontineli/Documents/study/enem-data-exploration/data/interim/unzipped_2023/DICIONµRIO/Dicion†rio_Microdados_Enem_2023.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = pd.read_parquet(PARQUET_IN)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m descriptions, categories = \u001b[43mread_enem_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDICT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLinhas:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df), \u001b[33m\"\u001b[39m\u001b[33m| Variáveis descritas:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(descriptions), \u001b[33m\"\u001b[39m\u001b[33m| Com categorias:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(categories))\n\u001b[32m      4\u001b[39m \u001b[38;5;28mlist\u001b[39m(categories.keys())[:\u001b[32m10\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mread_enem_dictionary\u001b[39m\u001b[34m(dict_path, sheet_name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_enem_dictionary\u001b[39m(dict_path: \u001b[38;5;28mstr\u001b[39m | Path, sheet_name: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mMICRODADOS_ENEM_2023\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# localizar colunas por palavras-chave (tolerante a acentos/maiúsculas)\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_col\u001b[39m(keyword):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/study/enem-data-exploration/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/study/enem-data-exploration/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/study/enem-data-exploration/.venv/lib/python3.13/site-packages/pandas/io/excel/_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/study/enem-data-exploration/.venv/lib/python3.13/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/gabrielfontineli/Documents/study/enem-data-exploration/data/interim/unzipped_2023/DICIONµRIO/Dicion†rio_Microdados_Enem_2023.xlsx'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_parquet(PARQUET_IN)\n",
    "descriptions, categories = read_enem_dictionary(DICT_PATH)\n",
    "print(\"Linhas:\", len(df), \"| Variáveis descritas:\", len(descriptions), \"| Com categorias:\", len(categories))\n",
    "list(categories.keys())[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b62c4",
   "metadata": {},
   "source": [
    "## 3) Aplicar rótulos às variáveis importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06dfc9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# TP_ESCOLA (fallback se não vier do dicionário)\u001b[39;00m\n\u001b[32m     13\u001b[39m tp_fallback = {\u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mNão respondeu\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPública\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPrivada\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m4\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mExterior\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m tp_cats = \u001b[43mcategories\u001b[49m.get(\u001b[33m\"\u001b[39m\u001b[33mTP_ESCOLA\u001b[39m\u001b[33m\"\u001b[39m, tp_fallback)\n\u001b[32m     15\u001b[39m tp_order = [\u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m3\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m4\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# Pública, Privada, Não resp., Exterior\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mTP_ESCOLA\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df.columns:\n",
      "\u001b[31mNameError\u001b[39m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def apply_labels(df, var, cats: dict, order_codes: list[str] | None = None, new_col=None):\n",
    "    if not cats:\n",
    "        return df\n",
    "    target = new_col or var\n",
    "    s = df[var].astype(\"string\")\n",
    "    # ordem: a que vier do dicionário (ou a fornecida)\n",
    "    order = order_codes or list(cats.keys())\n",
    "    labeled = s.map(cats).astype(\"category\").cat.set_categories([cats[k] for k in order], ordered=True)\n",
    "    df[target] = labeled\n",
    "    return df\n",
    "\n",
    "# TP_ESCOLA (fallback se não vier do dicionário)\n",
    "tp_fallback = {\"1\": \"Não respondeu\", \"2\": \"Pública\", \"3\": \"Privada\", \"4\": \"Exterior\"}\n",
    "tp_cats = categories.get(\"TP_ESCOLA\", tp_fallback)\n",
    "tp_order = [\"2\",\"3\",\"1\",\"4\"]  # Pública, Privada, Não resp., Exterior\n",
    "if \"TP_ESCOLA\" in df.columns:\n",
    "    df[\"TP_ESCOLA\"] = df[\"TP_ESCOLA\"].astype(\"Int64\").astype(\"string\")  # normaliza\n",
    "    df = apply_labels(df, \"TP_ESCOLA\", tp_cats, order_codes=tp_order, new_col=\"TP_ESCOLA_rot\")\n",
    "\n",
    "# Q001–Q006, Q022, Q024, Q025 (se existirem)\n",
    "for q in [\"Q001\",\"Q002\",\"Q003\",\"Q004\",\"Q005\",\"Q006\",\"Q022\",\"Q024\",\"Q025\"]:\n",
    "    if q in df.columns:\n",
    "        cats = categories.get(q, {})\n",
    "        if cats:\n",
    "            # ordem A..Z como padrão\n",
    "            order = sorted(cats.keys(), key=lambda x: x)\n",
    "            df[q] = df[q].astype(\"string\")\n",
    "            df = apply_labels(df, q, cats, order_codes=order, new_col=f\"{q}_rot\")\n",
    "        else:\n",
    "            # sem rótulo: mantém a original\n",
    "            pass\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74527631",
   "metadata": {},
   "source": [
    "## 4) Salvar versão rotulada (Parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52f9921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet rotulado salvo em: /Users/gabrielfontineli/Documents/study/enem-data-exploration/data/interim/enem_2023_rotulado.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.to_parquet(PARQUET_OUT, index=False)\n",
    "print(\"Parquet rotulado salvo em:\", PARQUET_OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc969e40",
   "metadata": {},
   "source": [
    "## 5) Figuras com rótulos — Boxplot por tipo de escola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cdadbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP_ESCOLA_rot não disponível.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if \"TP_ESCOLA_rot\" in df.columns:\n",
    "    plt.figure(figsize=(7,4))\n",
    "    df.boxplot(column=\"NOTA_MEDIA_5\", by=\"TP_ESCOLA_rot\", grid=False)\n",
    "    plt.title(\"NOTA_MEDIA_5 por Tipo de Escola — ENEM 2023 (rotulado)\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"Média das 5 provas\")\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / \"boxplot_media5_por_tp_escola_rotulado.png\"\n",
    "    plt.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Figura salva:\", out)\n",
    "else:\n",
    "    print(\"TP_ESCOLA_rot não disponível.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de524275",
   "metadata": {},
   "source": [
    "## 6) Tabela de mapeamentos (para relatório)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbe07121",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Exporta um CSV longo com var, código e rótulo\u001b[39;00m\n\u001b[32m      2\u001b[39m rows = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m var, mapping \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcategories\u001b[49m.items():\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m code, label \u001b[38;5;129;01min\u001b[39;00m mapping.items():\n\u001b[32m      5\u001b[39m         rows.append({\u001b[33m\"\u001b[39m\u001b[33mvariavel\u001b[39m\u001b[33m\"\u001b[39m: var, \u001b[33m\"\u001b[39m\u001b[33mcodigo\u001b[39m\u001b[33m\"\u001b[39m: code, \u001b[33m\"\u001b[39m\u001b[33mrotulo\u001b[39m\u001b[33m\"\u001b[39m: label})\n",
      "\u001b[31mNameError\u001b[39m: name 'categories' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exporta um CSV longo com var, código e rótulo\n",
    "rows = []\n",
    "for var, mapping in categories.items():\n",
    "    for code, label in mapping.items():\n",
    "        rows.append({\"variavel\": var, \"codigo\": code, \"rotulo\": label})\n",
    "map_df = pd.DataFrame(rows).sort_values([\"variavel\",\"codigo\"])\n",
    "out_csv = TAB_DIR / \"dicionario_mapeamentos.csv\"\n",
    "map_df.to_csv(out_csv, index=False)\n",
    "print(\"Mapeamentos salvos em:\", out_csv)\n",
    "map_df.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04db232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis descritas: 89\n",
      "Variáveis COM categorias: 0\n",
      "Exemplos: []\n"
     ]
    }
   ],
   "source": [
    "print(\"Variáveis descritas:\", len(descriptions))\n",
    "print(\"Variáveis COM categorias:\", len(categories))\n",
    "print(\"Exemplos:\", list(categories.keys())[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b25643",
   "metadata": {},
   "source": [
    "## 7) Tendência por renda (Q006_rot) com rótulos do dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a19ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"Q006_rot\" in df.columns and \"NOTA_MEDIA_5\" in df.columns:\n",
    "    tmp = df.dropna(subset=[\"Q006_rot\",\"NOTA_MEDIA_5\"]).copy()\n",
    "    # Usa a ordem categórica já aplicada\n",
    "    cats = list(tmp[\"Q006_rot\"].cat.categories)\n",
    "    m = tmp.groupby(\"Q006_rot\")[\"NOTA_MEDIA_5\"].mean().reindex(cats)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(range(len(m)), m.values, marker=\"o\")\n",
    "    plt.title(\"Média das 5 provas por faixa de renda (Q006) — Rotulada\")\n",
    "    plt.xlabel(\"Faixa de renda (Q006)\")\n",
    "    plt.ylabel(\"Média NOTA_MEDIA_5\")\n",
    "    plt.xticks(range(len(m)), cats, rotation=0, ha=\"center\")\n",
    "    # quebra rótulos longos\n",
    "    import textwrap\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels([\"\n",
    "\".join(textwrap.wrap(t, 20)) for t in cats])\n",
    "    plt.tight_layout()\n",
    "    out = FIG_DIR / \"linha_media5_por_q006_rotulada.png\"\n",
    "    plt.savefig(out, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    print(\"Figura salva:\", out)\n",
    "else:\n",
    "    print(\"Q006_rot ou NOTA_MEDIA_5 indisponíveis.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d665943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MICRODADOS_ENEM_2023', 'ITENS_PROVA_2023']\n",
      "===  MICRODADOS_ENEM_2023\n",
      "['DICIONÁRIO DE VARIÁVEIS - ENEM 2023', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
      "===  ITENS_PROVA_2023\n",
      "['ITENS', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "p = \"../data/interim/unzipped_2023/microdados_enem_2023/DICIONÁRIO/Dicionário_Microdados_Enem_2023.xlsx\"\n",
    "xls = pd.ExcelFile(p)\n",
    "print(xls.sheet_names)\n",
    "for sh in xls.sheet_names:\n",
    "    print(\"=== \", sh)\n",
    "    print(pd.read_excel(p, sheet_name=sh, nrows=5).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22ab665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --dict DICT --csv CSV --json JSON\n",
      "                             [--sheet SHEET]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --dict, --csv, --json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def read_enem_dict_2023_hierarchical(xlsx_path: Path, sheet=\"MICRODADOS_ENEM_2023\"):\n",
    "    # lê sem header fixo e depois aplica o cabeçalho correto (duas linhas abaixo do título)\n",
    "    raw = pd.read_excel(xlsx_path, sheet_name=sheet, header=None)\n",
    "    # encontra a linha do cabeçalho pela string \"NOME DA VAR\"\n",
    "    header_idx = raw.index[raw[0].astype(str).str.contains(\"NOME DA VAR\", na=False)][0]\n",
    "    # pula a linha seguinte (que tem \"Categoria | Descrição\" das categorias)\n",
    "    data = raw.iloc[header_idx+2:].copy()\n",
    "    data.columns = [\"VAR\",\"DESC\",\"CAT_CODE\",\"CAT_DESC\",\"TAMANHO\",\"TIPO\"]\n",
    "\n",
    "    descriptions = {}\n",
    "    categories   = {}\n",
    "    current_var  = None\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        var = row[\"VAR\"]\n",
    "        # nova variável começa quando \"VAR\" tem valor\n",
    "        if isinstance(var, str) and var.strip():\n",
    "            current_var = var.strip().upper()\n",
    "            desc = \"\" if pd.isna(row[\"DESC\"]) else str(row[\"DESC\"]).strip()\n",
    "            descriptions[current_var] = desc\n",
    "            # se a primeira linha já trouxer um código/descrição, captura\n",
    "            code = row[\"CAT_CODE\"]; label = row[\"CAT_DESC\"]\n",
    "            if pd.notna(code) and pd.notna(label):\n",
    "                code_str = str(int(code)) if isinstance(code, float) and code.is_integer() else str(code)\n",
    "                categories.setdefault(current_var, {})[code_str] = str(label).strip()\n",
    "        else:\n",
    "            # linhas de continuação: só códigos/descrições\n",
    "            if current_var is None:\n",
    "                continue\n",
    "            code = row[\"CAT_CODE\"]; label = row[\"CAT_DESC\"]\n",
    "            if pd.notna(code) and pd.notna(label):\n",
    "                code_str = str(int(code)) if isinstance(code, float) and code.is_integer() else str(code)\n",
    "                categories.setdefault(current_var, {})[code_str] = str(label).strip()\n",
    "\n",
    "    return descriptions, categories\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Gera arquivos de mapeamento (CSV/JSON) a partir do Dicionário dos Microdados ENEM.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dict\", required=True,\n",
    "        help=\"Caminho para o arquivo Dicionário_Microdados_Enem_2023.xlsx\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--csv\", required=True,\n",
    "        help=\"Caminho de saída para o arquivo CSV com mapeamentos\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--json\", required=True,\n",
    "        help=\"Caminho de saída para o arquivo JSON com mapeamentos\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sheet\", default=\"MICRODADOS_ENEM_2023\",\n",
    "        help=\"Nome da aba a ser lida (padrão: MICRODADOS_ENEM_2023)\"\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    xlsx_path = Path(args.dict)\n",
    "    out_csv = Path(args.csv)\n",
    "    out_json = Path(args.json)\n",
    "\n",
    "    # --- leitura principal (formato hierárquico) ---\n",
    "    print(f\"Lendo dicionário ENEM 2023 de: {xlsx_path}\")\n",
    "    descriptions, categories = read_enem_dict_2023_hierarchical(xlsx_path, sheet=args.sheet)\n",
    "\n",
    "    print(f\"Descrições encontradas: {len(descriptions)}\")\n",
    "    print(f\"Variáveis com categorias: {len(categories)}\")\n",
    "\n",
    "    # --- exportação ---\n",
    "    rows = []\n",
    "    for var, mapping in categories.items():\n",
    "        for code, label in mapping.items():\n",
    "            rows.append({\"variavel\": var, \"codigo\": code, \"rotulo\": label})\n",
    "\n",
    "    out_csv.parent.mkdir(parents=True, exist_ok=True)\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pd.DataFrame(rows).sort_values([\"variavel\", \"codigo\"]).to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    with open(out_json, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(categories, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"Arquivos salvos:\")\n",
    "    print(f\"  CSV : {out_csv}\")\n",
    "    print(f\"  JSON: {out_json}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
